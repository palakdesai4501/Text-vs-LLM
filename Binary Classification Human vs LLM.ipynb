{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b800faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d68d4f",
   "metadata": {},
   "source": [
    "# Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14be8bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>char_count</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Federal law supersedes state law, and cannabis...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>967</td>\n",
       "      <td>181</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>25.857143</td>\n",
       "      <td>57.30</td>\n",
       "      <td>967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Miles feels restless after working all day. He...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5068</td>\n",
       "      <td>924</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.661255</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>53.21</td>\n",
       "      <td>5068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>So first of I am danish. That means that I fol...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>1602</td>\n",
       "      <td>316</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>22.571429</td>\n",
       "      <td>61.97</td>\n",
       "      <td>1602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In this paper we present a novel rule-based ap...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5469</td>\n",
       "      <td>1015</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.564532</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>27.86</td>\n",
       "      <td>5469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Most social progressives, love democracy, and ...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>2379</td>\n",
       "      <td>437</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.752860</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>61.67</td>\n",
       "      <td>2379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text    source  \\\n",
       "0           0  Federal law supersedes state law, and cannabis...  Bloom-7B   \n",
       "1           1  Miles feels restless after working all day. He...  Bloom-7B   \n",
       "2           2  So first of I am danish. That means that I fol...  Bloom-7B   \n",
       "3           3  In this paper we present a novel rule-based ap...  Bloom-7B   \n",
       "4           4  Most social progressives, love democracy, and ...  Bloom-7B   \n",
       "\n",
       "   text_length  word_count     Prompt  lexical_diversity  avg_sentence_length  \\\n",
       "0          967         181  Undefined           0.806630            25.857143   \n",
       "1         5068         924  Undefined           0.661255            23.100000   \n",
       "2         1602         316  Undefined           0.718354            22.571429   \n",
       "3         5469        1015  Undefined           0.564532            40.600000   \n",
       "4         2379         437  Undefined           0.752860            23.000000   \n",
       "\n",
       "   readability_score  char_count  ...  embedding_40  embedding_41  \\\n",
       "0              57.30         967  ...     -0.035092     -0.001925   \n",
       "1              53.21        5068  ...     -0.003091     -0.043269   \n",
       "2              61.97        1602  ...      0.011013     -0.008409   \n",
       "3              27.86        5469  ...     -0.018165      0.012030   \n",
       "4              61.67        2379  ...      0.004131      0.014534   \n",
       "\n",
       "   embedding_42  embedding_43  embedding_44  embedding_45  embedding_46  \\\n",
       "0     -0.041666     -0.005266      0.034543      0.002532     -0.071304   \n",
       "1      0.003721     -0.005574      0.030584     -0.006616      0.030465   \n",
       "2      0.008066     -0.012316      0.007549     -0.000401     -0.001133   \n",
       "3     -0.020475     -0.006033      0.002823     -0.000594      0.000835   \n",
       "4      0.007382     -0.016189      0.007070      0.001430     -0.017871   \n",
       "\n",
       "   embedding_47  embedding_48  embedding_49  \n",
       "0      0.014727     -0.012865      0.004744  \n",
       "1      0.000941      0.020913      0.060853  \n",
       "2     -0.005499     -0.011693      0.000179  \n",
       "3      0.001109      0.009936     -0.019899  \n",
       "4      0.004868      0.010563      0.008097  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('corpus.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1f71b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(788922, 63)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d041bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>classification</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.806630</td>\n",
       "      <td>57.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.095722</td>\n",
       "      <td>-0.049095</td>\n",
       "      <td>-0.118440</td>\n",
       "      <td>-0.004019</td>\n",
       "      <td>0.043696</td>\n",
       "      <td>-0.116908</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.661255</td>\n",
       "      <td>53.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>-0.099866</td>\n",
       "      <td>0.107777</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>-0.063522</td>\n",
       "      <td>0.097034</td>\n",
       "      <td>0.091039</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.718354</td>\n",
       "      <td>61.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164173</td>\n",
       "      <td>0.117847</td>\n",
       "      <td>-0.012992</td>\n",
       "      <td>0.088472</td>\n",
       "      <td>0.097658</td>\n",
       "      <td>-0.002207</td>\n",
       "      <td>-0.073280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.564532</td>\n",
       "      <td>27.86</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.179447</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>0.155961</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>0.099195</td>\n",
       "      <td>-0.101426</td>\n",
       "      <td>-0.038001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.752860</td>\n",
       "      <td>61.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>-0.074277</td>\n",
       "      <td>0.031704</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>0.062544</td>\n",
       "      <td>-0.055907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>0.420610</td>\n",
       "      <td>36.22</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.157033</td>\n",
       "      <td>-0.008564</td>\n",
       "      <td>-0.079678</td>\n",
       "      <td>0.104863</td>\n",
       "      <td>-0.095362</td>\n",
       "      <td>0.039880</td>\n",
       "      <td>-0.053883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005222</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-0.023085</td>\n",
       "      <td>-0.030199</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>0.395532</td>\n",
       "      <td>29.08</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.282313</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>-0.078380</td>\n",
       "      <td>-0.014602</td>\n",
       "      <td>-0.034506</td>\n",
       "      <td>0.077010</td>\n",
       "      <td>0.023160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>-0.023404</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>0.026361</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>0.020802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>47.22</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.264905</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.106972</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>-0.192508</td>\n",
       "      <td>0.167850</td>\n",
       "      <td>-0.146308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>-0.001044</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.039127</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.072912</td>\n",
       "      <td>-0.009205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>0.476351</td>\n",
       "      <td>28.77</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.263766</td>\n",
       "      <td>0.064379</td>\n",
       "      <td>-0.021544</td>\n",
       "      <td>-0.112702</td>\n",
       "      <td>-0.044006</td>\n",
       "      <td>0.123673</td>\n",
       "      <td>0.041577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.035284</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>-0.011754</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.014060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>0.404580</td>\n",
       "      <td>31.82</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.193548</td>\n",
       "      <td>0.069151</td>\n",
       "      <td>-0.109348</td>\n",
       "      <td>0.181288</td>\n",
       "      <td>-0.049860</td>\n",
       "      <td>0.040569</td>\n",
       "      <td>0.085691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017204</td>\n",
       "      <td>-0.020792</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lexical_diversity  readability_score  classification  embedding_0  \\\n",
       "0                0.806630              57.30               1     0.008560   \n",
       "1                0.661255              53.21               1     0.070761   \n",
       "2                0.718354              61.97               1     0.164173   \n",
       "3                0.564532              27.86               1    -0.179447   \n",
       "4                0.752860              61.67               1     0.159706   \n",
       "...                   ...                ...             ...          ...   \n",
       "788917           0.420610              36.22               1    -0.157033   \n",
       "788918           0.395532              29.08               1    -0.282313   \n",
       "788919           0.447761              47.22               1    -0.264905   \n",
       "788920           0.476351              28.77               1    -0.263766   \n",
       "788921           0.404580              31.82               1    -0.193548   \n",
       "\n",
       "        embedding_1  embedding_2  embedding_3  embedding_4  embedding_5  \\\n",
       "0          0.095722    -0.049095    -0.118440    -0.004019     0.043696   \n",
       "1         -0.099866     0.107777     0.008168    -0.063522     0.097034   \n",
       "2          0.117847    -0.012992     0.088472     0.097658    -0.002207   \n",
       "3          0.010308     0.155961     0.029293     0.099195    -0.101426   \n",
       "4          0.083560    -0.074277     0.031704     0.066774     0.062544   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "788917    -0.008564    -0.079678     0.104863    -0.095362     0.039880   \n",
       "788918     0.034885    -0.078380    -0.014602    -0.034506     0.077010   \n",
       "788919    -0.011840     0.106972     0.034591    -0.192508     0.167850   \n",
       "788920     0.064379    -0.021544    -0.112702    -0.044006     0.123673   \n",
       "788921     0.069151    -0.109348     0.181288    -0.049860     0.040569   \n",
       "\n",
       "        embedding_6  ...  embedding_40  embedding_41  embedding_42  \\\n",
       "0         -0.116908  ...     -0.035092     -0.001925     -0.041666   \n",
       "1          0.091039  ...     -0.003091     -0.043269      0.003721   \n",
       "2         -0.073280  ...      0.011013     -0.008409      0.008066   \n",
       "3         -0.038001  ...     -0.018165      0.012030     -0.020475   \n",
       "4         -0.055907  ...      0.004131      0.014534      0.007382   \n",
       "...             ...  ...           ...           ...           ...   \n",
       "788917    -0.053883  ...     -0.005222     -0.001365     -0.020148   \n",
       "788918     0.023160  ...     -0.006157     -0.023404      0.037557   \n",
       "788919    -0.146308  ...      0.010574     -0.008166      0.018903   \n",
       "788920     0.041577  ...      0.013639      0.035284      0.000662   \n",
       "788921     0.085691  ...      0.017204     -0.020792      0.003079   \n",
       "\n",
       "        embedding_43  embedding_44  embedding_45  embedding_46  embedding_47  \\\n",
       "0          -0.005266      0.034543      0.002532     -0.071304      0.014727   \n",
       "1          -0.005574      0.030584     -0.006616      0.030465      0.000941   \n",
       "2          -0.012316      0.007549     -0.000401     -0.001133     -0.005499   \n",
       "3          -0.006033      0.002823     -0.000594      0.000835      0.001109   \n",
       "4          -0.016189      0.007070      0.001430     -0.017871      0.004868   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788917     -0.023085     -0.030199     -0.012152      0.002733     -0.000128   \n",
       "788918      0.026361     -0.008231      0.023823     -0.009165     -0.004096   \n",
       "788919     -0.001044     -0.037097      0.025732      0.039127      0.018915   \n",
       "788920      0.023736      0.030208      0.013736     -0.011754     -0.010964   \n",
       "788921      0.026649      0.001552      0.009237      0.019272      0.000913   \n",
       "\n",
       "        embedding_48  embedding_49  \n",
       "0          -0.012865      0.004744  \n",
       "1           0.020913      0.060853  \n",
       "2          -0.011693      0.000179  \n",
       "3           0.009936     -0.019899  \n",
       "4           0.010563      0.008097  \n",
       "...              ...           ...  \n",
       "788917      0.022612     -0.007202  \n",
       "788918     -0.016606      0.020802  \n",
       "788919      0.072912     -0.009205  \n",
       "788920      0.000265      0.014060  \n",
       "788921      0.027279      0.002167  \n",
       "\n",
       "[788922 rows x 53 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 0', 'text', 'prompt_length', 'source', \n",
    "         'text_length', 'word_count', 'Prompt', \n",
    "         'avg_sentence_length', 'char_count', \n",
    "         'sentence_count'], axis=1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68fa3beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    441230\n",
       "0    347692\n",
       "Name: classification, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d2823f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.806630</td>\n",
       "      <td>57.30</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.095722</td>\n",
       "      <td>-0.049095</td>\n",
       "      <td>-0.118440</td>\n",
       "      <td>-0.004019</td>\n",
       "      <td>0.043696</td>\n",
       "      <td>-0.116908</td>\n",
       "      <td>-0.008107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.661255</td>\n",
       "      <td>53.21</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>-0.099866</td>\n",
       "      <td>0.107777</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>-0.063522</td>\n",
       "      <td>0.097034</td>\n",
       "      <td>0.091039</td>\n",
       "      <td>0.015570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.718354</td>\n",
       "      <td>61.97</td>\n",
       "      <td>0.164173</td>\n",
       "      <td>0.117847</td>\n",
       "      <td>-0.012992</td>\n",
       "      <td>0.088472</td>\n",
       "      <td>0.097658</td>\n",
       "      <td>-0.002207</td>\n",
       "      <td>-0.073280</td>\n",
       "      <td>-0.042987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.564532</td>\n",
       "      <td>27.86</td>\n",
       "      <td>-0.179447</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>0.155961</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>0.099195</td>\n",
       "      <td>-0.101426</td>\n",
       "      <td>-0.038001</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.752860</td>\n",
       "      <td>61.67</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>-0.074277</td>\n",
       "      <td>0.031704</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>0.062544</td>\n",
       "      <td>-0.055907</td>\n",
       "      <td>-0.002149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>0.420610</td>\n",
       "      <td>36.22</td>\n",
       "      <td>-0.157033</td>\n",
       "      <td>-0.008564</td>\n",
       "      <td>-0.079678</td>\n",
       "      <td>0.104863</td>\n",
       "      <td>-0.095362</td>\n",
       "      <td>0.039880</td>\n",
       "      <td>-0.053883</td>\n",
       "      <td>-0.106344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005222</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-0.023085</td>\n",
       "      <td>-0.030199</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>0.395532</td>\n",
       "      <td>29.08</td>\n",
       "      <td>-0.282313</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>-0.078380</td>\n",
       "      <td>-0.014602</td>\n",
       "      <td>-0.034506</td>\n",
       "      <td>0.077010</td>\n",
       "      <td>0.023160</td>\n",
       "      <td>0.014074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>-0.023404</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>0.026361</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>0.020802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>47.22</td>\n",
       "      <td>-0.264905</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.106972</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>-0.192508</td>\n",
       "      <td>0.167850</td>\n",
       "      <td>-0.146308</td>\n",
       "      <td>-0.042047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>-0.001044</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.039127</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.072912</td>\n",
       "      <td>-0.009205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>0.476351</td>\n",
       "      <td>28.77</td>\n",
       "      <td>-0.263766</td>\n",
       "      <td>0.064379</td>\n",
       "      <td>-0.021544</td>\n",
       "      <td>-0.112702</td>\n",
       "      <td>-0.044006</td>\n",
       "      <td>0.123673</td>\n",
       "      <td>0.041577</td>\n",
       "      <td>-0.016348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.035284</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>-0.011754</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.014060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>0.404580</td>\n",
       "      <td>31.82</td>\n",
       "      <td>-0.193548</td>\n",
       "      <td>0.069151</td>\n",
       "      <td>-0.109348</td>\n",
       "      <td>0.181288</td>\n",
       "      <td>-0.049860</td>\n",
       "      <td>0.040569</td>\n",
       "      <td>0.085691</td>\n",
       "      <td>-0.085746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017204</td>\n",
       "      <td>-0.020792</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lexical_diversity  readability_score  embedding_0  embedding_1  \\\n",
       "0                0.806630              57.30     0.008560     0.095722   \n",
       "1                0.661255              53.21     0.070761    -0.099866   \n",
       "2                0.718354              61.97     0.164173     0.117847   \n",
       "3                0.564532              27.86    -0.179447     0.010308   \n",
       "4                0.752860              61.67     0.159706     0.083560   \n",
       "...                   ...                ...          ...          ...   \n",
       "788917           0.420610              36.22    -0.157033    -0.008564   \n",
       "788918           0.395532              29.08    -0.282313     0.034885   \n",
       "788919           0.447761              47.22    -0.264905    -0.011840   \n",
       "788920           0.476351              28.77    -0.263766     0.064379   \n",
       "788921           0.404580              31.82    -0.193548     0.069151   \n",
       "\n",
       "        embedding_2  embedding_3  embedding_4  embedding_5  embedding_6  \\\n",
       "0         -0.049095    -0.118440    -0.004019     0.043696    -0.116908   \n",
       "1          0.107777     0.008168    -0.063522     0.097034     0.091039   \n",
       "2         -0.012992     0.088472     0.097658    -0.002207    -0.073280   \n",
       "3          0.155961     0.029293     0.099195    -0.101426    -0.038001   \n",
       "4         -0.074277     0.031704     0.066774     0.062544    -0.055907   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "788917    -0.079678     0.104863    -0.095362     0.039880    -0.053883   \n",
       "788918    -0.078380    -0.014602    -0.034506     0.077010     0.023160   \n",
       "788919     0.106972     0.034591    -0.192508     0.167850    -0.146308   \n",
       "788920    -0.021544    -0.112702    -0.044006     0.123673     0.041577   \n",
       "788921    -0.109348     0.181288    -0.049860     0.040569     0.085691   \n",
       "\n",
       "        embedding_7  ...  embedding_40  embedding_41  embedding_42  \\\n",
       "0         -0.008107  ...     -0.035092     -0.001925     -0.041666   \n",
       "1          0.015570  ...     -0.003091     -0.043269      0.003721   \n",
       "2         -0.042987  ...      0.011013     -0.008409      0.008066   \n",
       "3          0.011437  ...     -0.018165      0.012030     -0.020475   \n",
       "4         -0.002149  ...      0.004131      0.014534      0.007382   \n",
       "...             ...  ...           ...           ...           ...   \n",
       "788917    -0.106344  ...     -0.005222     -0.001365     -0.020148   \n",
       "788918     0.014074  ...     -0.006157     -0.023404      0.037557   \n",
       "788919    -0.042047  ...      0.010574     -0.008166      0.018903   \n",
       "788920    -0.016348  ...      0.013639      0.035284      0.000662   \n",
       "788921    -0.085746  ...      0.017204     -0.020792      0.003079   \n",
       "\n",
       "        embedding_43  embedding_44  embedding_45  embedding_46  embedding_47  \\\n",
       "0          -0.005266      0.034543      0.002532     -0.071304      0.014727   \n",
       "1          -0.005574      0.030584     -0.006616      0.030465      0.000941   \n",
       "2          -0.012316      0.007549     -0.000401     -0.001133     -0.005499   \n",
       "3          -0.006033      0.002823     -0.000594      0.000835      0.001109   \n",
       "4          -0.016189      0.007070      0.001430     -0.017871      0.004868   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788917     -0.023085     -0.030199     -0.012152      0.002733     -0.000128   \n",
       "788918      0.026361     -0.008231      0.023823     -0.009165     -0.004096   \n",
       "788919     -0.001044     -0.037097      0.025732      0.039127      0.018915   \n",
       "788920      0.023736      0.030208      0.013736     -0.011754     -0.010964   \n",
       "788921      0.026649      0.001552      0.009237      0.019272      0.000913   \n",
       "\n",
       "        embedding_48  embedding_49  \n",
       "0          -0.012865      0.004744  \n",
       "1           0.020913      0.060853  \n",
       "2          -0.011693      0.000179  \n",
       "3           0.009936     -0.019899  \n",
       "4           0.010563      0.008097  \n",
       "...              ...           ...  \n",
       "788917      0.022612     -0.007202  \n",
       "788918     -0.016606      0.020802  \n",
       "788919      0.072912     -0.009205  \n",
       "788920      0.000265      0.014060  \n",
       "788921      0.027279      0.002167  \n",
       "\n",
       "[788922 rows x 52 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['classification'], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff8554ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "788917    1\n",
       "788918    1\n",
       "788919    1\n",
       "788920    1\n",
       "788921    1\n",
       "Name: classification, Length: 788922, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['classification']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fbda0b",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b489155",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a01013f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(631137, 52)\n",
      "(157785, 52)\n",
      "(631137,)\n",
      "(157785,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d516a415",
   "metadata": {},
   "source": [
    "# Oversampling using ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0b70274",
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn = ADASYN()\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce89544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.417978</td>\n",
       "      <td>44.030000</td>\n",
       "      <td>-0.028298</td>\n",
       "      <td>0.235729</td>\n",
       "      <td>-0.119890</td>\n",
       "      <td>0.012450</td>\n",
       "      <td>-0.049655</td>\n",
       "      <td>0.020836</td>\n",
       "      <td>0.081456</td>\n",
       "      <td>-0.005956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>-0.019959</td>\n",
       "      <td>-0.014821</td>\n",
       "      <td>-0.011888</td>\n",
       "      <td>0.007007</td>\n",
       "      <td>-0.031287</td>\n",
       "      <td>-0.029798</td>\n",
       "      <td>-0.009144</td>\n",
       "      <td>0.020187</td>\n",
       "      <td>-0.004240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.486331</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>-0.285594</td>\n",
       "      <td>0.093629</td>\n",
       "      <td>-0.020098</td>\n",
       "      <td>0.058807</td>\n",
       "      <td>-0.011897</td>\n",
       "      <td>-0.027218</td>\n",
       "      <td>0.125155</td>\n",
       "      <td>0.024640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.021283</td>\n",
       "      <td>0.021422</td>\n",
       "      <td>0.014839</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>0.024329</td>\n",
       "      <td>0.036614</td>\n",
       "      <td>0.011967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.649682</td>\n",
       "      <td>69.820000</td>\n",
       "      <td>0.145476</td>\n",
       "      <td>0.205359</td>\n",
       "      <td>-0.022710</td>\n",
       "      <td>0.031460</td>\n",
       "      <td>0.078788</td>\n",
       "      <td>-0.054157</td>\n",
       "      <td>-0.091834</td>\n",
       "      <td>-0.065708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020616</td>\n",
       "      <td>-0.001738</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>0.023713</td>\n",
       "      <td>0.038916</td>\n",
       "      <td>-0.024163</td>\n",
       "      <td>-0.015902</td>\n",
       "      <td>0.029937</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.008091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.419780</td>\n",
       "      <td>70.630000</td>\n",
       "      <td>0.096494</td>\n",
       "      <td>-0.160023</td>\n",
       "      <td>-0.079883</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>-0.138550</td>\n",
       "      <td>-0.047022</td>\n",
       "      <td>0.121929</td>\n",
       "      <td>-0.046468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038442</td>\n",
       "      <td>0.023495</td>\n",
       "      <td>0.057251</td>\n",
       "      <td>-0.003178</td>\n",
       "      <td>-0.038109</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>-0.019907</td>\n",
       "      <td>-0.017387</td>\n",
       "      <td>-0.003197</td>\n",
       "      <td>0.020420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.891892</td>\n",
       "      <td>81.120000</td>\n",
       "      <td>0.223751</td>\n",
       "      <td>0.181031</td>\n",
       "      <td>0.009854</td>\n",
       "      <td>0.031525</td>\n",
       "      <td>-0.223295</td>\n",
       "      <td>-0.051569</td>\n",
       "      <td>0.006036</td>\n",
       "      <td>0.027013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.077965</td>\n",
       "      <td>0.020868</td>\n",
       "      <td>0.022083</td>\n",
       "      <td>0.025668</td>\n",
       "      <td>-0.011525</td>\n",
       "      <td>-0.015577</td>\n",
       "      <td>0.059956</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>-0.005578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685952</th>\n",
       "      <td>0.657538</td>\n",
       "      <td>35.931440</td>\n",
       "      <td>0.023408</td>\n",
       "      <td>0.062457</td>\n",
       "      <td>-0.049270</td>\n",
       "      <td>0.046745</td>\n",
       "      <td>0.054091</td>\n",
       "      <td>0.008605</td>\n",
       "      <td>-0.059339</td>\n",
       "      <td>-0.039116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002946</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.008364</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>-0.013800</td>\n",
       "      <td>-0.007865</td>\n",
       "      <td>0.009997</td>\n",
       "      <td>-0.005235</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.008428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685953</th>\n",
       "      <td>0.597901</td>\n",
       "      <td>81.830000</td>\n",
       "      <td>0.200792</td>\n",
       "      <td>0.107150</td>\n",
       "      <td>-0.025438</td>\n",
       "      <td>0.051745</td>\n",
       "      <td>0.054845</td>\n",
       "      <td>-0.030241</td>\n",
       "      <td>-0.062238</td>\n",
       "      <td>-0.019535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004963</td>\n",
       "      <td>0.017622</td>\n",
       "      <td>-0.007000</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>-0.013099</td>\n",
       "      <td>-0.015952</td>\n",
       "      <td>0.011508</td>\n",
       "      <td>0.017696</td>\n",
       "      <td>0.005992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685954</th>\n",
       "      <td>0.608811</td>\n",
       "      <td>51.953921</td>\n",
       "      <td>0.100465</td>\n",
       "      <td>-0.031739</td>\n",
       "      <td>-0.008198</td>\n",
       "      <td>0.057046</td>\n",
       "      <td>0.103455</td>\n",
       "      <td>-0.022977</td>\n",
       "      <td>-0.003092</td>\n",
       "      <td>-0.019296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008456</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>-0.013819</td>\n",
       "      <td>-0.002907</td>\n",
       "      <td>-0.020004</td>\n",
       "      <td>-0.024598</td>\n",
       "      <td>-0.005972</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>-0.002226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685955</th>\n",
       "      <td>0.802853</td>\n",
       "      <td>97.540000</td>\n",
       "      <td>0.090853</td>\n",
       "      <td>-0.052084</td>\n",
       "      <td>0.177980</td>\n",
       "      <td>-0.074527</td>\n",
       "      <td>-0.129642</td>\n",
       "      <td>-0.084174</td>\n",
       "      <td>-0.005751</td>\n",
       "      <td>-0.118104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088023</td>\n",
       "      <td>0.029923</td>\n",
       "      <td>0.035215</td>\n",
       "      <td>-0.034485</td>\n",
       "      <td>-0.078118</td>\n",
       "      <td>-0.009134</td>\n",
       "      <td>-0.036494</td>\n",
       "      <td>0.042401</td>\n",
       "      <td>0.091348</td>\n",
       "      <td>-0.008648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685956</th>\n",
       "      <td>0.721283</td>\n",
       "      <td>66.101734</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.172663</td>\n",
       "      <td>0.047046</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>0.020263</td>\n",
       "      <td>-0.047546</td>\n",
       "      <td>0.056012</td>\n",
       "      <td>-0.009470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013964</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.012173</td>\n",
       "      <td>0.020076</td>\n",
       "      <td>0.018474</td>\n",
       "      <td>0.012467</td>\n",
       "      <td>-0.011323</td>\n",
       "      <td>-0.029718</td>\n",
       "      <td>-0.001715</td>\n",
       "      <td>-0.006884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>685957 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lexical_diversity  readability_score  embedding_0  embedding_1  \\\n",
       "0                0.417978          44.030000    -0.028298     0.235729   \n",
       "1                0.486331          18.350000    -0.285594     0.093629   \n",
       "2                0.649682          69.820000     0.145476     0.205359   \n",
       "3                0.419780          70.630000     0.096494    -0.160023   \n",
       "4                0.891892          81.120000     0.223751     0.181031   \n",
       "...                   ...                ...          ...          ...   \n",
       "685952           0.657538          35.931440     0.023408     0.062457   \n",
       "685953           0.597901          81.830000     0.200792     0.107150   \n",
       "685954           0.608811          51.953921     0.100465    -0.031739   \n",
       "685955           0.802853          97.540000     0.090853    -0.052084   \n",
       "685956           0.721283          66.101734     0.000580     0.172663   \n",
       "\n",
       "        embedding_2  embedding_3  embedding_4  embedding_5  embedding_6  \\\n",
       "0         -0.119890     0.012450    -0.049655     0.020836     0.081456   \n",
       "1         -0.020098     0.058807    -0.011897    -0.027218     0.125155   \n",
       "2         -0.022710     0.031460     0.078788    -0.054157    -0.091834   \n",
       "3         -0.079883     0.027915    -0.138550    -0.047022     0.121929   \n",
       "4          0.009854     0.031525    -0.223295    -0.051569     0.006036   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "685952    -0.049270     0.046745     0.054091     0.008605    -0.059339   \n",
       "685953    -0.025438     0.051745     0.054845    -0.030241    -0.062238   \n",
       "685954    -0.008198     0.057046     0.103455    -0.022977    -0.003092   \n",
       "685955     0.177980    -0.074527    -0.129642    -0.084174    -0.005751   \n",
       "685956     0.047046     0.005272     0.020263    -0.047546     0.056012   \n",
       "\n",
       "        embedding_7  ...  embedding_40  embedding_41  embedding_42  \\\n",
       "0         -0.005956  ...      0.049609     -0.019959     -0.014821   \n",
       "1          0.024640  ...     -0.001384     -0.021283      0.021422   \n",
       "2         -0.065708  ...     -0.020616     -0.001738      0.019349   \n",
       "3         -0.046468  ...     -0.038442      0.023495      0.057251   \n",
       "4          0.027013  ...     -0.011595     -0.077965      0.020868   \n",
       "...             ...  ...           ...           ...           ...   \n",
       "685952    -0.039116  ...     -0.002946      0.000684      0.008364   \n",
       "685953    -0.019535  ...     -0.004963      0.017622     -0.007000   \n",
       "685954    -0.019296  ...      0.008456      0.002493      0.001082   \n",
       "685955    -0.118104  ...      0.088023      0.029923      0.035215   \n",
       "685956    -0.009470  ...      0.013964      0.008392      0.012173   \n",
       "\n",
       "        embedding_43  embedding_44  embedding_45  embedding_46  embedding_47  \\\n",
       "0          -0.011888      0.007007     -0.031287     -0.029798     -0.009144   \n",
       "1           0.014839      0.016114     -0.000148     -0.003200      0.024329   \n",
       "2           0.023713      0.038916     -0.024163     -0.015902      0.029937   \n",
       "3          -0.003178     -0.038109      0.003587     -0.019907     -0.017387   \n",
       "4           0.022083      0.025668     -0.011525     -0.015577      0.059956   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "685952      0.006608     -0.013800     -0.007865      0.009997     -0.005235   \n",
       "685953      0.005769      0.006044     -0.013099     -0.015952      0.011508   \n",
       "685954     -0.013819     -0.002907     -0.020004     -0.024598     -0.005972   \n",
       "685955     -0.034485     -0.078118     -0.009134     -0.036494      0.042401   \n",
       "685956      0.020076      0.018474      0.012467     -0.011323     -0.029718   \n",
       "\n",
       "        embedding_48  embedding_49  \n",
       "0           0.020187     -0.004240  \n",
       "1           0.036614      0.011967  \n",
       "2           0.007026      0.008091  \n",
       "3          -0.003197      0.020420  \n",
       "4           0.007639     -0.005578  \n",
       "...              ...           ...  \n",
       "685952      0.000944      0.008428  \n",
       "685953      0.017696      0.005992  \n",
       "685954      0.004125     -0.002226  \n",
       "685955      0.091348     -0.008648  \n",
       "685956     -0.001715     -0.006884  \n",
       "\n",
       "[685957 rows x 52 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27a6dbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    353116\n",
       "0    332841\n",
       "Name: classification, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f8670",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5cb7b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_clf = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "log_reg_clf.fit(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "678a96ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70     69671\n",
      "           1       0.77      0.71      0.74     88114\n",
      "\n",
      "    accuracy                           0.72    157785\n",
      "   macro avg       0.72      0.72      0.72    157785\n",
      "weighted avg       0.73      0.72      0.72    157785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_logreg = log_reg_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_hat_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01882409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7214754254206673"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_accuracy = accuracy_score(y_test, y_hat_logreg)\n",
    "logreg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849e3d4",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6fdd7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knn_clf = KNeighborsClassifier()\n",
    "\n",
    "Knn_clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87b752c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78     69671\n",
      "           1       0.87      0.71      0.78     88114\n",
      "\n",
      "    accuracy                           0.78    157785\n",
      "   macro avg       0.79      0.79      0.78    157785\n",
      "weighted avg       0.80      0.78      0.78    157785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_knn = Knn_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_hat_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1599cd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7809107329594068"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_accuracy = accuracy_score(y_test, y_hat_knn)\n",
    "knn_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a07ef3",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a67e1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf_model = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "rf_clf_model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f512436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85     69671\n",
      "           1       0.88      0.90      0.89     88114\n",
      "\n",
      "    accuracy                           0.87    157785\n",
      "   macro avg       0.87      0.87      0.87    157785\n",
      "weighted avg       0.87      0.87      0.87    157785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_rfc = rf_clf_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_hat_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d06d7ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8734100199638749"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_accuracy = accuracy_score(y_test, y_hat_rfc)\n",
    "rf_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0b089",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3c5f90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Define hyperparameters to search\\nrf_param_grid = {\\n    'n_estimators': [200, 300],\\n    'min_samples_split': [2, 5, 10],\\n    'min_samples_leaf': [1, 2, 4],\\n    'criterion': ['gini','entropy']\\n}\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Define hyperparameters to search\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini','entropy']\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "097a98a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.model_selection import GridSearchCV\\n\\nrf_clf_hpt = GridSearchCV(estimator=rf_clf_model, param_grid=rf_param_grid, cv=5, scoring='accuracy', verbose=3)\\n\\nrf_clf_hpt.fit(X_resampled, y_resampled)\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_clf_hpt = GridSearchCV(estimator=rf_clf_model, param_grid=rf_param_grid, cv=5, scoring='accuracy', verbose=3)\n",
    "\n",
    "rf_clf_hpt.fit(X_resampled, y_resampled)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f7186",
   "metadata": {},
   "source": [
    "# Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de86ac4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = ['Logistic Regression', 'Random Forest Classifier', 'K-Nearest Neighbor Classifier']\n",
    "\n",
    "accuracy_scores = [round(logreg_accuracy, 2), round(rf_accuracy, 2), round(knn_accuracy, 2)]\n",
    "\n",
    "plt.figure(figsize=[10,5])\n",
    "plt.bar(models, accuracy_scores, color=['maroon', 'lightgreen', 'lightblue'])\n",
    "\n",
    "plt.ylabel('Accuracy Score')\n",
    "\n",
    "for i in range(len(models)):\n",
    "    plt.text(i,accuracy_scores[i], str(accuracy_scores[i]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e1f74",
   "metadata": {},
   "source": [
    "# Save the model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53e84ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('binaryclf_rf.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_clf_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1750f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b027b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
